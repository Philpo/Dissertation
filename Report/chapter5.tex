\chapter{Data Analysis and Evaluation}
\label{sec:eval}

This chapter will present and analyse the data gathered with the test plan detailed in the previous chapter. It will also evaluate the project hypotheses using the gathered data.

\section{Chosen Parameters}
The first stage of the data collection process was to choose suitable values for the parameters detailed previously.

\subsection{Mesh Size}
The maximum mesh size used was 300$^{2}$; this is the largest mesh size the can be run at real time frame rates with the most expensive integrator (RK4). This maximum was decreased by 50 in both dimensions, to a minimum size of 50$^{2}$, to give the six mesh sizes below.
\begin{itemize}
\item{300$^{2}$}
\item{250$^{2}$}
\item{200$^{2}$}
\item{150$^{2}$}
\item{100$^{2}$}
\item{50$^{2}$}
\end{itemize}

\subsection{Time Step}
The maximum time step was 20ms. This was the largest time step where at least one integrator was still stable for a 50$^{2}$ mesh. This value was decreased by 5ms giving the range of five time steps listed below.
\begin{itemize}
\item{20ms}
\item{15ms}
\item{10ms}
\item{5ms}
\item{1ms}
\end{itemize}

\subsection{Mass and Spring and Damping Coefficients}
These parameters were kept constant for every mesh size to avoid changing more than one variable between tests. Values were chosen that gave a reasonable cloth appearance. There are some visual issues, such as too much oscillation, with the values chosen at the larger mesh sizes but this is acceptable due to the focus of the project. The values used are as follows:
\begin{itemize}
\item{Mass = 100}
\item{Structural Stiffness = 20}
\item{Structural Damping = 7.5}
\item{Shear Stiffness = 20}
\item{Shear Damping = 7.5}
\item{Flexion Stiffness = 5}
\item{Flexion Damping = 2.5}
\end{itemize}
For Verlet, a constant damping factor of 0.5\% was used.

\section{Results}

\subsection{Explicit Euler}
Fig \ref{fig:ee fps sheet} shows the average simulation frame rate for every time step at every mesh size, in the sheet scenario. Only data for stable simulations are shown. The graph shows two things, firstly that as mesh size increases average frame rate decreases and secondly that as time step increases average frame rate increases.
\\\\The data shows that varying mesh size can have a dramatic effect on the frame rate, this is shown well by Fig \ref{fig:ee mesh fps sheet}. This graph uses the average FPS for a 1ms time step, so that only one variable is changed. It has a strong negative correlation, with a Pearson's correlation coefficient of -0.8751. Also, it clearly shows a dramatic frame rate decrease as mesh size is increased to 100$^{2}$ and 150$^{2}$; for a 100$^{2}$ mesh the decrease is approximately 1.4 times and for 150$^{2}$ approximately 6.8 times.
\\The decrease in frame rate can be explained by examining where the time each frame is spent. Fig \ref{fig:ee ft sheet} shows that the majority of the frame time is spent in the update function for a 300$^{2}$ mesh using a 1ms time step. This is the worst case test, but the conclusion is reflected across all other mesh sizes and time steps. By plotting the average time spent in the update function against mesh size, it is possible to explain why the frame rate decreases. Fig \ref{fig:ee mesh update sheet} shows this graph; as with Fig \ref{fig:ee mesh fps sheet} it shows data for a 1ms time step. This shows a strong positive correlation, of strength 0.9626, thus it can be concluded that update time increases with mesh size. If the time for each update increases with mesh size, then the total time for each frame must increase also, thus reducing the frame rate of the simulation. 
\\Digging a little deeper, Fig \ref{fig:ee ut sheet} shows that calculating the internal forces, i.e. the spring forces, is the most expensive part of each update. By plotting this against mesh size, shown in Fig \ref{fig:ee mesh csf sheet}, a strong positive correlation is again observed, with Pearson's coefficient 0.9302. This is easy to explain. As mesh size increases, the number of particles increases, and therefore the number of springs also increases. More springs means that Equations \ref{eq:hooke equation} and \ref{eq:spring damping} must be calculated more, hence the time spent on internal forces increases.
\\\\The increase in update time with mesh size also explains the increase in frame rate as the time step increases. As the time step increases, the expensive update function is called less frequently, so overall frame time is decreased, thus increasing the frame rate. Fig \ref{fig:ee step fps sheet} shows the average frame rate plotted against the time step for a 300$^{2}$ mesh. This graph has a Pearson's correlation of 0.8955, thus supporting that frame rate increases with time step. It also shows that frame rate only increases once the time step exceeds some threshold. Again, this result can be explained by examining the average update time. For the 300$^{2}$ mesh, the average update time was approximately 6ms, and frame rate only increased once the time step reaches 10ms. The reason for this should be obvious; both the 1ms and 5ms time steps are less than the total update time, therefore the update function will still be called every frame.
\\\\As mentioned earlier, only those simulations that are stable are shown in Fig \ref{fig:ee fps sheet}. From this graph, and the data in Table \ref{tab:ee stability sheet} it is obvious that explicit Euler is quite unstable. It is only really stable for a 1ms time step, apart from for a 50$^{2}$ mesh, where it is stable for a 5ms step.
\\\\The data for the flag scenario shows similar correlations to the sheet scenario. Figs \ref{fig:ee fps flag} and \ref{fig:ee mesh fps flag} show that as mesh size increases FPS decreases, with a strong negative correlation of strength -0.8163. The same initial dramatic decreases as the sheet scenario are still present; the decrease for a 100$^{2}$ mesh is approximately 2.8 times and approximately 4.9 times for 150$^{2}$. As with the sheet scenario, the majority of the frame time is still spent within update (see Fig \ref{fig:ee ft flag}) and Fig \ref{fig:ee mesh update flag} displays a strong positive correlation as well, with Pearson's correlation of 0.9682.
\\The frame rates for the flag scenario are slightly lower than those for the sheet, this is explained by looking at Fig \ref{fig:ee ut flag}. It shows a slightly different time breakdown within the update function. Calculating the internal forces is still the most expensive part, but the cost of calculating external forces has risen significantly over the sheet scenario; an approximate increase of 6.8 times. This is because the flag scenario includes wind as an additional external force. In order to apply wind, the particles must be split into triangles and the surface normal of every triangle calculated at every time step. 
\\Figs \ref{fig:ee fps flag} and \ref{fig:ee step fps flag} show that as time step increases the FPS increases with it, displaying a strong positive correlation of 0.9568. They also support the conclusion that frame rate only increases once the time step exceeds the total update time; again the frame rate for the 300$^{2}$ mesh only increased at 10ms, because the average update time was approximately 8ms.
\\The stability of the flag scenario tests, listed in Table \ref{tab:ee stability flag} are also similar to the sheet scenario, with the only difference being that a 5ms time step and 100$^{2}$ mesh was stable for the flag scenario.
\\\\\crefrange{fig:ee box 50 sheet}{fig:ee box 300 sheet} and \crefrange{fig:ee box 50 flag}{fig:ee box 300 flag} are the boxplots of the data for the explicit Euler integrator. They show that there is quite a lot of variance in the data gathered, particularly at lower mesh sizes. Mean values are used for the results detailed above, however examining the raw data, listed in Tables \ref{tab:ee raw sheet} and \ref{tab:ee raw flag}, shows that the correlations are consistent for any particular test run.
\\\\Overall, explicit Euler is efficient. It easily supports the largest mesh size with a 1ms time step, running at 197 and 120FPS for the sheet and flag scenarios respectively, well over the 30FPS limit needed for a real time system. The update times for the same mesh are only 6 and 8ms, respectively, as well, which leaves approximately 27 and 25ms available each frame for other game related functions. The caveat is that it is only really stable for a 1ms time step, so the cloth will be updated frequently. However, as has been shown, the low cost of the integrator counters this disadvantage somewhat.

\subsection{Verlet}
The data for Verlet integration shows similar trends to explicit Euler.
\\Fig \ref{fig:v fps sheet} shows the average FPS decreases as mesh size increases for Verlet integration. This is supported by Fig \ref{fig:v mesh fps sheet} which has a strong negative correlation with Pearson's coefficient of -0.8486. Both graphs also show a dramatic frame rate decrease as mesh size is increased to 100$^{2}$ and 150$^{2}$; approximately 2.1 and 6.5 times respectively with a 1ms time step. Again, this is explained by Figs \ref{fig:v ft sheet} and \ref{fig:v mesh update sheet} which show that the update function continues to be the most expensive code path and that update time has a positive correlation, of strength 0.9619, as mesh size increases. Calculating the internal forces continues to be the most expensive part of update, as shown in Fig \ref{fig:v ut sheet}, and similar to explicit Euler, displays a positive correlation with mesh size (Fig \ref{fig:v mesh csf sheet}), with a Pearson's coefficient of 0.9679.
\\Fig \ref{fig:v fps sheet} also shows that frame rate increases as the time step increases. This is supported by Fig \ref{fig:v step fps sheet} as it shows a positive correlation, with a coefficient of 0.8963, for FPS as time step increases. As with explicit Euler, both graphs show that the frame rate only increases once the time step exceeds some threshold. Again, this is because the update time for the 300$^{2}$ mesh is roughly 6ms.
\\The stability of Verlet can be seen in Table \ref{tab:v stability sheet} and Fig \ref{fig:v fps sheet}. It shows that Verlet is much more stable than explicit Euler, being stable for every time step for the 50$^{2}$ mesh and even stable with a 5ms time step for 150$^{2}$ and 200$^{2}$ meshes. This increased stability may be a result of the damping factor added in Equation \ref{eq:dampened verlet}. Even with the small damping factor used (0.5\%), the damping was much more noticeable than other integrators.
\\\\Similarly, the flag scenario also displays the same trends as the sheet scenario. Figs \ref{fig:v fps flag} and \ref{fig:v mesh fps flag} both show a negative correlation for FPS as mesh size increases, with Pearson's correlation coefficient of -0.7709. Again large initial decreases are shown; approximately 4.2 times for 100$^{2}$ and approximately 4.8 times for 150$^{2}$. The majority of the frame time is still spent within update (see Fig \ref{fig:v ft flag}) and Fig \ref{fig:v mesh update flag} has a Pearson's correlation coefficient of 0.9678 for update time.
\\As with explicit Euler, Fig \ref{fig:v ut flag} shows that the cost of calculating external forces has risen significantly over the sheet scenario; approximately 6.8 times. This is reflected in the frame rate, and explains why the frame rates for the flag scenario are lower than the sheet scenario.
\\The trend that FPS increases with time step is also reflected in the flag scenario; Figs \ref{fig:v fps flag} and \ref{fig:v step fps sheet} show a positive correlation for FPS as time step increases, with a coefficient of 0.9579. Again, the same time step thresholds as explicit Euler are observed.
\\The stability of the flag scenario tests, listed in Table \ref{tab:v stability flag} are identical to the sheet scenario, supporting the conclusion that Verlet is more stable than explicit Euler.
\\\\The boxplots for Verlet are shown in \crefrange{fig:v box 50 sheet}{fig:v box 300 sheet} and \crefrange{fig:v box 50 flag}{fig:v box 300 flag}. Again there is quite a lot of variance in the data, particularly at lower mesh sizes. The correlations presented above however, are again reflected across individual tests in the data, listed in Tables \ref{tab:v raw sheet} and \ref{tab:v raw flag}.
\\\\Since Verlet is much more stable it offers performance advantages over explicit Euler. For example, for a 200$^{2}$ mesh, explicit Euler is limited to a 1ms time step which results in frame rates of 474 and 289 for the sheet and flag scenarios. By contrast, Verlet is stable for a 5ms time step leading to a frame rate of 6563 and 3574 for the two scenarios, an increase of approximately 13.8 and 12.4 times respectively. For mesh sizes over 200$^{2}$ however, Verlet is limited to a 1ms time step as well, so is more comparable to explicit Euler.
\\The data for the 50$^{2}$ mesh is quite anomalous. Comparing Verlet with explicit Euler reveals drastically different frame rates; this is shown well in \crefrange{fig:1ms fps sheet}{fig:5ms fps sheet} and \crefrange{fig:1ms fps flag}{fig:5ms fps flag}. It is clear from these graphs that Verlet has much higher frame rates for a 50$^{2}$ mesh, with differences of roughly 3500-4000FPS. This is not expected, the expected behaviour is that Verlet has roughly the same performance as explicit Euler. The graphs show that other mesh sizes display the expected behaviour, so the results from the 50$^{2}$ mesh should be excluded as an anomaly.
\\Since the damping equation \ref{eq:spring damping} is useless for Verlet, it may be possible to increase the performance by adding an if check to the calcSpringForce function in the Spring class that would not calculate \ref{eq:spring damping} when using Verlet integration.

\subsection{Midpoint}
As with the previous integrators, the data for Midpoint displays similar trends.
\\Figs \ref{fig:m fps sheet}, \ref{fig:m mesh fps sheet}, \ref{fig:m fps flag} and \ref{fig:m mesh fps flag} all show that both the sheet and flag scenarios have a similar negative correlation to that displayed by the previous integrators, with coefficients of -0.7076 and -0.6941. Yet again there is a large initial drop in frame rate as the mesh size is changed to 100$^{2}$, but the decreases become smaller from that point. This is because the drop for the 100$^{2}$ mesh is much larger than explicit Euler or Verlet; approximately 10.5 and 13.8 times for the two scenarios. This explains why the Pearson's correlation coefficients for FPS as mesh size increases are smaller than the other integrators. With Midpoint, after the large initial frame rate drop, the changes become much smaller, which results, overall, in a less steep correlation.
\\Figs \ref{fig:m fps sheet} and \ref{fig:m fps flag} continue to show the same positive correlation between FPS and time step for both scenarios, a conclusion also supported by Figs \ref{fig:m step fps sheet} and \ref{fig:m step fps flag}, which have correlation coefficients of 0.9651 and 0.9699 respectively. The same thresholding phenomenon is also observed, but it is more exaggerated for the Midpoint integrator. For the sheet scenario, the 300$^{2}$ mesh has an increased threshold of 10ms and for the flag scenario it has a threshold of 15ms.
\\Figs \ref{fig:m ft sheet} and \ref{fig:m ft flag} explain why the threshold values have increased. The graphs show that the average time spent in the update function has increased over the previous integrators by almost 2 times. This is expected, as the Midpoint integrator involves two derivatives, so the forces acting on the cloth must be calculated twice. Consequently, it is expected that the average time spent calculating the forces should increase as well, a theory supported by Figs \ref{fig:m ut sheet} and \ref{fig:m ut flag}, both of which show that force calculation times have almost doubled. As a result of this increased update time, the frame rates for Midpoint are often significantly lower than both explicit Euler and Verlet.
\\The stability of the integrator is shown in Tables \ref{tab:m stability sheet} and \ref{tab:m stability flag}. It shows that Midpoint is only slightly more stable than explicit Euler but much less stable than Verlet; it is stable up to 10ms for the 50$^{2}$ mesh, but unstable with time steps greater than 1ms for every other mesh size.
\\\\The boxplots for Midpoint, shown in \crefrange{fig:m box 50 sheet}{fig:m box 300 sheet} and \crefrange{fig:m box 50 flag}{fig:m box 300 flag}, present similar results as the other integrators. There is still a reasonably large variance in data, but the trends described are consistent in the raw data, listed in Tables \ref{tab:m raw sheet} and \ref{tab:m raw flag}, for individual tests
\\\\The data shows that, as expected, Midpoint is roughly twice as expensive as explicit Euler and Verlet and slightly more stable than explicit Euler. As a result, for small mesh sizes (50$^{2}$ or below), the Midpoint integrator is a better choice than explicit Euler as it has increased performance due to the larger stable time step. However, as with Verlet, the data for the 50$^{2}$ mesh is highly anomalous, and so should not be used to draw conclusions. For anything other than small meshes, Midpoint is not recommended, as it is only stable with a 1ms time step which is too small to counteract the increased cost of the integrator.

\subsection{Fourth Order Runge-Kutta}
RK4 extends the trends displayed by Midpoint; notably lower frame rates, increased update times and increased time step thresholds.
\\Figs \ref{fig:rk4 fps sheet} and \ref{fig:rk4 fps flag} show the lower frame rates of RK4. As with all the other integrators, there is still a clear negative correlation between average FPS and mesh size, a fact shown more clearly by Figs \ref{fig:rk4 mesh fps sheet} and \ref{fig:rk4 mesh fps flag}, with correlation coefficients of -0.6999 and -0.74 respectively. Large initial decreases in frame rate are observed, again with a 100$^{2}$ mesh giving the most dramatic decreases; roughly 12.7 and 6.3 times for the two scenarios. As with Midpoint, the size of this initial frame rate decrease explains why the correlation coefficients are slightly lower.
\\Figs \ref{fig:rk4 fps sheet} and \ref{fig:rk4 fps flag} and \ref{fig:rk4 step fps sheet} and \ref{fig:rk4 step fps flag} continue to show a positive correlation for frame rate as time step increases; the latter graphs have Pearson's coefficients of 0.8802 and 0.8889 respectively. The latter graphs also highlight the significantly lower frame rates for RK4; both scenarios show FPS numbers less than 60, with the flag scenario dropping below 30FPS for a 1ms time step.
\\RK4 requires four derivates, therefore it is expected that the total update time should be roughly twice as large as the Midpoint integrator. Figs \ref{fig:rk4 ft sheet} and \ref{fig:rk4 ft flag} show that total update time is indeed roughly double that of Midpoint. These large update times explains why RK4 has many more time step thresholds than the other integrators. For both scenarios, the 300$^{2}$ mesh no longer has any time step that increases frame rate. The increase in time step thresholds explains why Fig \ref{fig:rk4 fps sheet} shows an FPS drop for a 150$^{2}$ mesh with a 5ms time step. That mesh size has a time step threshold of 10ms, so it is expected that frame rate shouldn't increase for a 5ms time step. The slight performance decrease probably arises from expected variations in the data, but as the difference is not huge, this drop is not concerning.
\\The performance delta between the sheet and flag scenarios is much more pronounced for RK4. This is because there are larger differences between the update times for the scenarios using RK4 than other integrators. Figs \ref{fig:rk4 ft sheet} and \ref{fig:rk4 ft flag} show that for a 300$^{2}$ mesh with a 1ms time step the update time difference between the scenarios is almost 10ms. This is much larger than Midpoint, where the difference between scenarios is only approximately 4ms. Figs \ref{fig:rk4 mesh update sheet} and \ref{fig:rk4 mesh update flag} highlight the update time differences as well, in particular highlighting that as mesh size increases, the time differences get wider.
\\\\Looking at the boxplots, \crefrange{fig:rk4 box 50 sheet}{fig:rk4 box 300 sheet} show that for the sheet scenario, RK4 is consistent with the other integrators, having quite a lot of variance in the data. For the flag scenario, \crefrange{fig:rk4 box 50 flag}{fig:rk4 box 300 flag} show less variance than the other integrators. This may be because the update times are so high that there is less possibility of variation. As with all the other integrators, examining the raw data in Tables \ref{tab:rk4 raw sheet} and \ref{tab:rk4 raw flag} shows that the trends identified are consistent across multiple test runs, despite the variation.
\\\\Tables \ref{tab:rk4 stability sheet} and \ref{tab:rk4 stability flag} list the stability of RK4 in both scenarios. They show that, as expected, RK4 is more stable than explicit Euler and Midpoint; stable up to 15ms for 50$^{2}$ meshes, and 5ms for mesh sizes up to 150$^{2}$. At 50$^{2}$ this stability is enough to counter the very high cost of RK4. However examinations of other integrators has chosen the 50$^{2}$ data to be anomalous so it cannot be used to recommend RK4. Sadly at all other mesh size, these time steps are not large enough to counter the very expensive computation of this integrator and therefore there are no situations in which RK4 should be chosen ahead of explicit Euler or Midpoint.

\section{Evaluation}

\subsection{Null Hypothesis}
The null hypothesis for this project is that all integration methods result in real time cloth simulation when running on modern hardware.
\\Whilst the data analysed above does indeed show that all the integrators result in real time simulations, this is only true for the small number of mesh sizes used in the testing process. The data, summarised in Figs \ref{fig:1ms fps sheet} and \ref{fig:1ms fps flag}, clearly show a negative correlation for frame rate as mesh size increases for all integrators. Hence, if mesh size were increased beyond the maximum used here, performance would decay even further, eventually resulting in non real time simulations. This frame rate decrease comes as a result of the cost of calculating each update step increasing with mesh size. Therefore, the only way to prevent the FPS loss is to use a larger time step to calculate less updates. However, the stability analysis shows that none of the integrators are stable with a time step greater than 1ms for larger mesh sizes, so there is no way of avoiding the performance loss. This disproves the null hypothesis and shows that performance is still very much a concern for Mass-Spring models, even when running on modern hardware.

\subsection{Alternative Hypothesis}
The alternative hypothesis is that some integration methods are prohibitively expensive for real time simulations and that other methods give better performance.
\\This hypothesis is easily proven as the data clearly shows large performance deltas between some of the integrators (Figs \ref{fig:1ms fps sheet} and \ref{fig:1ms fps flag} show this particularly well). There is also a clear negative correlation between FPS and mesh size, so if mesh size were increased beyond 300$^{2}$, some integrators would quickly not give real time results.
\\The results however are different from what was expected. At the beginning of this project it was expected that the explicit Euler and Verlet integrators would be the least performant, as they were dependant on small time steps only. Midpoint and RK4 were expected to be more performant, as they would be stable for larger time steps, which would counteract their increased computational cost. This turned out not to be the case. For larger mesh sizes, none of the integrators are stable for time steps larger than 1ms so the cheaper integrators end up giving the best performance results. Figs \ref{fig:1ms fps sheet} and \ref{fig:5ms fps sheet} and \ref{fig:1ms fps flag} and \ref{fig:5ms fps flag} suggest that for a 50$^{2}$ mesh the expensive integrators would give performance gains over explicit Euler, thanks to their increased stability. However, the data for this mesh size is considered highly anomalous. This is due to the extremely large performance deltas between Verlet and explicit Euler, which at all other mesh sizes are shown to have roughly identical performance. Therefore, the 50$^{2}$ mesh cannot be used to draw conclusions about integrator performance.